{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common libraries loaded\n"
     ]
    }
   ],
   "source": [
    "%run \"libraries.ipynb\"\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonoverlapping function word categories\n",
    "\n",
    "- PP: personal pronouns (I, you)\n",
    "- IP: impersonal pronouns (this, it)\n",
    "- A: articles (a, the)\n",
    "- AV: auxiliary verbs (am, have)\n",
    "- ADV: high-frequency adverbs (very, well)\n",
    "- P: prepositions (in, around)\n",
    "- C: conjunctions (but, while)\n",
    "- N: negations (not, no)\n",
    "- Q: quantifiers (many, few)\n",
    "\n",
    "#### references\n",
    "\n",
    "- Ireland (2010)\n",
    "- Gonzales (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = wekeypedia.WikipediaPage(\"Love\")\n",
    "txt = page.get_revision()\n",
    "txt = BeautifulSoup(txt, \"html.parser\")\n",
    "txt = txt.get_text()\n",
    "txt = txt.replace(\"[edit]\",\"\")\n",
    "# print txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_tagged = nltk.pos_tag(nltk.word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PRP$': [u'your', u'his', u'your', u'its', u'its', u'his', u'their', u'his', u'your', u'his'], 'VBG': [u'being', u'Following', u'being', u'witnessing', u'including', u'hinting', u'lasting', u'being', u'dating', u'starting'], 'VBD': [u'needed', u'had', u'was', u'combined', u'believed', u'maintained', u'were', u'wrote', u'was', u'love'], 'VBN': [u'quoted', u'phrased', u'summarised', u'used', u'influenced', u'clarified', u'opposed', u'viewed', u'developed', u'attempted'], 'VBP': [u'love', u'are', u'are', u'are', u'come', u'love', u'have', u'have', u'love', u'love'], 'WDT': [u'which', u'that', u'which', u'that', u'which', u'that', u'that', u'which', u'which', u'which'], 'JJ': [u\"Qur'an\", u'similar', u'mammalian', u'monogamous', u'Italian', u'passionate', u'specific', u'important', u'other', u'infant'], 'WP': [u'who', u'what', u'who', u'what', u'who', u'who', u'what', u'What', u'who', u'who'], 'VBZ': [u'is', u'depends', u'versus', u'flows', u'is', u'has', u'is', u'has', u'becomes', u'is'], 'DT': [u'an', u'Some', u'a', u'an', u'The', u'a', u'the', u'the', u'the', u'The'], 'RP': [u'up'], 'NN': [u'observantia', u'liberation', u'psychology', u'form', u'and/or', u'love', u'love', u'marriage', u'familiarity', u'love'], 'POS': [u\"'s\", u\"'s\", u\"'s\", u\"'\", u\"'\", u\"'s\", u\"'s\", u\"'s\", u\"'s\", u\"'s\"], 'TO': [u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to'], 'PRP': [u'us', u'I', u'it', u'him', u'you', u'It', u'you', u'I', u'he', u'you'], 'RB': [u'often', u'only', u'also', u'however', u'also', u'However', u'usually', u'away', u'also', u'sometimes'], 'NNS': [u'developments', u'kinds', u'women', u'chemicals', u'worlds', u'others', u'acts', u'words', u'eros', u'definitions'], 'NNP': [u'Philosophical', u'Loving', u'Journal', u'Quran', u'Belur', u'Buddhism', u'Swami.', u'Love', u'Sacred', u'Review'], 'VB': [u'take', u'have', u'behave', u'remain', u'enlightenment', u'be', u'be', u'be', u'sleep', u'love'], 'WRB': [u'when', u'where', u'how', u'when', u'how', u'when', u'how', u'Why', u'When', u'when'], 'CC': [u'and', u'and', u'and', u'and', u'and', u'and', u'or', u'and', u'and', u'and'], 'PDT': [u'all'], 'RBS': [u'most', u'most', u'most', u'most'], 'RBR': [u'more', u'more', u'further', u'more', u'more', u'more', u'more', u'more', u'more', u'more'], 'CD': [u']', u'1988', u']', u'2000', u'2013', u'7', u'14', u']', u'1', u'11:90'], 'EX': [u'there', u'there', u'there', u'There', u'there', u'there', u'there', u'there', u'There', u'there'], 'IN': [u'as', u'in', u'in', u'with', u'with', u'in', u'among', u'love', u'as', u'with'], 'WP$': [u'whose'], 'MD': [u'can', u'can', u'could', u'can', u'would', u'might', u'may', u'can', u'should', u'can'], 'NNPS': [u'Romans', u'Its', u'Works', u'Christians', u'Types', u'Christians', u'Confucians', u'Americans', u'Romans', u'Activities'], 'JJS': [u'rest', u'best', u'Most', u'most', u'best', u'most', u'guest', u'Most', u'most', u'strongest'], 'JJR': [u'hunger', u'higher', u'stronger', u'consider', u'more', u'character', u'more', u'more', u'less', u'less']}\n"
     ]
    }
   ],
   "source": [
    "tags = defaultdict(list)\n",
    "\n",
    "lsm = {\n",
    "  \"personal pronouns\": [],\n",
    "  \"impersonal pronouns\": [],\n",
    "  \"articles\": [],\n",
    "  \"auxiliary verbs\": [],\n",
    "  \"hf adverbs\": [],\n",
    "  \"prepositions\": [],\n",
    "  \"conjunctions\": [],\n",
    "  \"negations\": [],\n",
    "  \"quantifiers\": []\n",
    "}\n",
    "\n",
    "for (word, tag) in text_tagged:\n",
    "  tags[tag].append(word)\n",
    "\n",
    "for i in [\"''\", \",\", \".\", \"``\", \":\", \"-NONE-\"]:\n",
    "  tags.pop(i, None)\n",
    "            \n",
    "print { tag: random.sample(words, min(len(words),10)) for (tag, words) in tags.iteritems() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### personal and impersonal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "104\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "pt = [ tags[tag] for tag in tags.keys() if tag.startswith('PRP') ]\n",
    "pt = [ p for pl in pt for p in pl ]\n",
    "\n",
    "impersonal = [\"it\", \"this\", \"that\", \"its\", \"anything\" ]\n",
    "\n",
    "lsm[\"personal pronouns\"] = [ p for p in pt if not(p.lower() in impersonal) ] \n",
    "lsm[\"impersonal pronouns\"] = [ p for p in pt if p.lower() in impersonal ] \n",
    "\n",
    "print len(pt)\n",
    "print len(lsm[\"personal pronouns\"])\n",
    "print len(lsm[\"impersonal pronouns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n"
     ]
    }
   ],
   "source": [
    "lsm[\"articles\"] = tags[\"DT\"]\n",
    "\n",
    "print len(lsm[\"articles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auxiliary verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "vt = [ tags[tag] for tag in tags.keys() if tag.startswith('V') ]\n",
    "vt = [ v for vl in vt for v in vl ]\n",
    "\n",
    "# for verb in vt:\n",
    "#     v = lemmatizer.lemmatize(verb, nltk.corpus.wordnet.VERB)\n",
    "#     print \"%s ---> %s\" % (verb, v)\n",
    "\n",
    "aux_verbs = [ \"be\", \"have\", \"do\", \"will\" ]\n",
    "\n",
    "lsm[\"auxiliary verbs\"] = [ verb for verb in vt if lemmatizer.lemmatize(verb, nltk.corpus.wordnet.VERB) in aux_verbs ]\n",
    "    \n",
    "print len(lsm[\"auxiliary verbs\"])\n",
    "# print lsm[\"auxiliary verbs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high-frequency adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advt = tags[\"RB\"]\n",
    "\n",
    "#print advt\n",
    "\n",
    "lsm[\"hf adverbs\"] = [ w for w in advt if w.lower() in [ \"often\", \"well\", \"very\", \"frequently\", \"generally\" ] ]\n",
    "\n",
    "len(lsm[\"hf adverbs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsm[\"prepositions\"] = tags[\"IN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "lsm[\"conjunctions\"] = tags[\"CC\"]\n",
    "\n",
    "print len(lsm[\"conjunctions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advt = tags[\"RB\"]\n",
    "\n",
    "lsm[\"negations\"] = [ w for w in advt if w.lower() in [ \"not\", \"no\", \"never\" ] ]\n",
    "\n",
    "len(lsm[\"negations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "qt = [ tags[tag] for tag in [\"JJ\", \"JJR\", \"DT\", \"PDT\" ] ]\n",
    "qt = [ q for ql in qt for q in ql ]\n",
    "\n",
    "quants = [ \"all\", \"any\", \"both\", \"each\", \"enough\", \"every\", \"few\", \"fewer\",\n",
    "          \"little\", \"less\", \"lots\", \"many\", \"more\", \"several\", \"some\" ] \n",
    "\n",
    "# for w in quants:\n",
    "#     print [ tag for tag in tags.keys() if w in tags[tag] ]\n",
    "\n",
    "lsm[\"quantifiers\"] = [ w for w in qt if w.lower() in quants ]\n",
    "\n",
    "print len(lsm[\"quantifiers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## page coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224\n",
      "657\n",
      "7.12272333044\n"
     ]
    }
   ],
   "source": [
    "print len(text_tagged)\n",
    "print len([ x for t in lsm.keys() for x in lsm[t] ])\n",
    "\n",
    "print 100*float(len([ x for t in lsm.keys() for x in lsm[t] ]))/float(len(text_tagged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
