{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common libraries loaded\n"
     ]
    }
   ],
   "source": [
    "%run \"libraries.ipynb\"\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonoverlapping function word categories\n",
    "\n",
    "- PP: personal pronouns (I, you)\n",
    "- IP: impersonal pronouns (this, it)\n",
    "- A: articles (a, the)\n",
    "- AV: auxiliary verbs (am, have)\n",
    "- ADV: high-frequency adverbs (very, well)\n",
    "- P: prepositions (in, around)\n",
    "- C: conjunctions (but, while)\n",
    "- N: negations (not, no)\n",
    "- Q: quantifiers (many, few)\n",
    "\n",
    "#### references\n",
    "\n",
    "- Ireland (2010)\n",
    "- Gonzales (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = wekeypedia.WikipediaPage(\"Love\")\n",
    "txt = page.get_revision()\n",
    "txt = BeautifulSoup(txt, \"html.parser\")\n",
    "txt = txt.get_text()\n",
    "txt = txt.replace(\"[edit]\",\"\")\n",
    "# print txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_tagged = nltk.pos_tag(nltk.word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PRP$': [u'its', u'your', u'his', u'its', u'their', u'its', u'their', u'their', u'their', u'its'], 'VBG': [u'according', u'attaining', u'hinting', u'experiencing', u'spelling', u'including', u'being', u'being', u'dating', u'loving'], 'VBD': [u'love', u'was', u'created', u'wrote', u'championed', u'published', u'experienced', u'felt', u'said', u'related'], 'VBN': [u'been', u'given', u'distinguished', u'interpreted', u'coined', u'born', u'found', u'used', u'called', u'eleven'], 'VBP': [u'love', u'love', u'prefer', u'believe', u'believe', u'see', u'regard', u'love', u'have', u'call'], 'WDT': [u'that', u'that', u'which', u'that', u'which', u'that', u'which', u'which', u'that', u'that'], 'JJ': [u'music', u'hypothetical', u'unselfish', u'human', u'semantic', u'human', u'Ancient', u'natural', u'much', u'sexual'], 'WP': [u'who', u'who', u'what', u'what', u'who', u'who', u'what', u'who', u'who', u'who'], 'VBZ': [u'is', u'Is', u'is', u'attitudes', u'is', u'has', u'works', u'indicates', u'is', u'links'], 'DT': [u'a', u'The', u'no', u'the', u'some', u'the', u'a', u'a', u'a', u'the'], 'RP': [u'up'], 'NN': [u'article', u'word', u'place', u'part', u'unity', u'dictionary', u'root', u'love', u'life', u'tenderness'], 'POS': [u\"'s\", u\"'s\", u\"'s\", u\"'\", u\"'s\", u\"'\", u\"'s\", u\"'s\", u\"'s\", u\"'s\"], 'TO': [u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to', u'to'], 'PRP': [u'It', u'it', u'you', u'It', u'He', u'he', u'you', u'it', u'it', u'it'], 'RB': [u'also', u'ago', u'not', u'well', u'not', u'only', u'also', u'lust', u'often', u'often'], 'NNS': [u'beings', u'discusses', u'feelings', u'meanings', u'laments', u'tasks', u'parents', u'makes', u'children', u'concepts'], 'NNP': [u'Augustine', u'(', u'Rabbinic', u'Breakup', u'Swami', u'Sufism', u'Polliti', u'God', u'Soren', u'God'], 'VB': [u'be', u'be', u'be', u'include', u'love', u'be', u'work', u'love', u'condemn', u'refer'], 'WRB': [u'how', u'when', u'when', u'how', u'when', u'how', u'Why', u'when', u'When', u'where'], 'CC': [u'and', u'or', u'and', u'and', u'and', u'or', u'and', u'and', u'and', u'and'], 'PDT': [u'all'], 'RBS': [u'most', u'most', u'most', u'most'], 'RBR': [u'more', u'more', u'more', u'further', u'more', u'more', u'more', u'more', u'more', u'more'], 'CD': [u')', u'one', u']', u'three', u'1', u'13\\u201314', u'9', u'1984', u')', u'21'], 'EX': [u'there', u'there', u'there', u'there', u'There', u'there', u'there', u'there', u'There', u'there'], 'IN': [u'as', u'from', u'of', u'on', u'of', u'of', u'in', u'of', u'about', u'in'], 'WP$': [u'whose'], 'MD': [u'may', u'can', u'may', u'would', u'can', u'can', u'can', u'can', u'will', u'may'], 'NNPS': [u'Practices', u'Americans', u'Types', u'Works', u'Romans', u'Christians', u'Christians', u'Activities', u'Romans', u'Meanings'], 'JJS': [u'most', u'most', u'guest', u'Most', u'best', u'rest', u'greatest', u'Most', u'best', u'strongest'], 'JJR': [u'less', u'more', u'more', u'less', u'hunger', u'character', u'higher', u'stronger', u'greater', u'more']}\n"
     ]
    }
   ],
   "source": [
    "tags = defaultdict(list)\n",
    "\n",
    "lsm = {\n",
    "  \"personal pronouns\": [],\n",
    "  \"impersonal pronouns\": [],\n",
    "  \"articles\": [],\n",
    "  \"auxiliary verbs\": [],\n",
    "  \"hf adverbs\": [],\n",
    "  \"prepositions\": [],\n",
    "  \"conjunctions\": [],\n",
    "  \"negations\": [],\n",
    "  \"quantifiers\": []\n",
    "}\n",
    "\n",
    "for (word, tag) in text_tagged:\n",
    "  tags[tag].append(word)\n",
    "\n",
    "for i in [\"''\", \",\", \".\", \"``\", \":\", \"-NONE-\"]:\n",
    "  tags.pop(i, None)\n",
    "            \n",
    "print { tag: random.sample(words, min(len(words),10)) for (tag, words) in tags.iteritems() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### personal and impersonal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "104\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "pt = [ tags[tag] for tag in tags.keys() if tag.startswith('PRP') ]\n",
    "pt = [ p for pl in pt for p in pl ]\n",
    "\n",
    "impersonal = [\"it\", \"this\", \"that\", \"its\", \"anything\" ]\n",
    "\n",
    "lsm[\"personal pronouns\"] = [ p for p in pt if not(p.lower() in impersonal) ] \n",
    "lsm[\"impersonal pronouns\"] = [ p for p in pt if p.lower() in impersonal ] \n",
    "\n",
    "print len(pt)\n",
    "print len(lsm[\"personal pronouns\"])\n",
    "print len(lsm[\"impersonal pronouns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n"
     ]
    }
   ],
   "source": [
    "lsm[\"articles\"] = tags[\"DT\"]\n",
    "\n",
    "print len(lsm[\"articles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auxiliary verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "vt = [ tags[tag] for tag in tags.keys() if tag.startswith('V') ]\n",
    "vt = [ v for vl in vt for v in vl ]\n",
    "\n",
    "# for verb in vt:\n",
    "#     v = lemmatizer.lemmatize(verb, nltk.corpus.wordnet.VERB)\n",
    "#     print \"%s ---> %s\" % (verb, v)\n",
    "\n",
    "aux_verbs = [ \"be\", \"have\", \"do\", \"will\" ]\n",
    "\n",
    "lsm[\"auxiliary verbs\"] = [ verb for verb in vt if lemmatizer.lemmatize(verb, nltk.corpus.wordnet.VERB) in aux_verbs ]\n",
    "    \n",
    "print len(lsm[\"auxiliary verbs\"])\n",
    "# print lsm[\"auxiliary verbs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high-frequency adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advt = tags[\"RB\"]\n",
    "\n",
    "#print advt\n",
    "\n",
    "lsm[\"hf adverbs\"] = [ w for w in advt if w.lower() in [ \"often\", \"well\", \"very\", \"frequently\", \"generally\" ] ]\n",
    "\n",
    "len(lsm[\"hf adverbs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsm[\"prepositions\"] = tags[\"IN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "lsm[\"conjunctions\"] = tags[\"CC\"]\n",
    "\n",
    "print len(lsm[\"conjunctions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advt = tags[\"RB\"]\n",
    "\n",
    "lsm[\"negations\"] = [ w for w in advt if w.lower() in [ \"not\", \"no\", \"never\" ] ]\n",
    "\n",
    "len(lsm[\"negations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "qt = [ tags[tag] for tag in [\"JJ\", \"JJR\", \"DT\", \"PDT\" ] ]\n",
    "qt = [ q for ql in qt for q in ql ]\n",
    "\n",
    "quants = [ \"all\", \"any\", \"both\", \"each\", \"enough\", \"every\", \"few\", \"fewer\",\n",
    "          \"little\", \"less\", \"lots\", \"many\", \"more\", \"several\", \"some\" ] \n",
    "\n",
    "# for w in quants:\n",
    "#     print [ tag for tag in tags.keys() if w in tags[tag] ]\n",
    "\n",
    "lsm[\"quantifiers\"] = [ w for w in qt if w.lower() in quants ]\n",
    "\n",
    "print len(lsm[\"quantifiers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## page coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224\n",
      "2455\n",
      "26.6153512576\n"
     ]
    }
   ],
   "source": [
    "print len(text_tagged)\n",
    "print len([ x for t in lsm.keys() for x in lsm[t] ])\n",
    "\n",
    "print 100*float(len([ x for t in lsm.keys() for x in lsm[t] ]))/float(len(text_tagged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
