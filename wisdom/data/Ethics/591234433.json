{
  "comment": "Fix [[Help:CS1_errors#deprecated_params|CS1 deprecated date parameter errors]]",
  "timestamp": "2014-01-18T06:24:24Z",
  "revid": 591234433,
  "user": "Monkbot",
  "parentid": 590642340,
  "diff": {
    "to": 591234433,
    "*": "<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 104:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 104:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Pragmatic ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Pragmatic ethics====</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Pragmatic ethics}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Pragmatic ethics}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>Associated with the [[pragmatism|pragmatists]], [[Charles Sanders Peirce]], [[William James]], and especially [[John Dewey]], pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).&lt;ref name=Lafollette2000&gt;{{Cite book | editor-first= Hugh | editor-last= Lafollette | series = Blackwell Philosophy Guides | edition = 1 | url= http://www.hughlafollette.com/papers/pragmati.htm |<del class=\"diffchange diffchange-inline\"> year </del>= 2000<del class=\"diffchange diffchange-inline\"> | month=February</del> | title = The Blackwell Guide to Ethical Theory | isbn = 978-0-631-20119-9 | publisher = [[Wiley-Blackwell]] | ref = harv}}&lt;/ref&gt;</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>Associated with the [[pragmatism|pragmatists]], [[Charles Sanders Peirce]], [[William James]], and especially [[John Dewey]], pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).&lt;ref name=Lafollette2000&gt;{{Cite book | editor-first= Hugh | editor-last= Lafollette | series = Blackwell Philosophy Guides | edition = 1 | url= http://www.hughlafollette.com/papers/pragmati.htm |<ins class=\"diffchange diffchange-inline\">date</ins>=<ins class=\"diffchange diffchange-inline\">February</ins> 2000 | title = The Blackwell Guide to Ethical Theory | isbn = 978-0-631-20119-9 | publisher = [[Wiley-Blackwell]] | ref = harv}}&lt;/ref&gt;</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Role ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Role ethics====</div></td>\n</tr>\n<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 181:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 181:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Machine ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Machine ethics====</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen |<del class=\"diffchange diffchange-inline\"> year </del>= 2008<del class=\"diffchange diffchange-inline\"> | month=November</del> | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-0-19-537404-9 | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen |<ins class=\"diffchange diffchange-inline\">date</ins>=<ins class=\"diffchange diffchange-inline\">November</ins> 2008 | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-0-19-537404-9 | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Military ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Military ethics====</div></td>\n</tr>\n\n<!-- diff cache key enwiki:diff:version:1.11a:oldid:590642340:newid:591234433 -->\n",
    "from": 590642340
  },
  "minor": ""
}