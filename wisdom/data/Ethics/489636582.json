{
  "comment": "/* Machine ethics */ war against boys",
  "timestamp": "2012-04-28T15:25:44Z",
  "revid": 489636582,
  "anon": "",
  "user": "41.219.160.203",
  "parentid": 489469890,
  "diff": {
    "to": 489636582,
    "*": "<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 108:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 108:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen | year = 2008 | month=November | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-0195374049 | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen | year = 2008 | month=November | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-0195374049 | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n</tr>\n<tr>\n  <td colspan=\"2\" class=\"diff-empty\">&#160;</td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"></td>\n</tr>\n<tr>\n  <td colspan=\"2\" class=\"diff-empty\">&#160;</td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>No one has yet identified the hidden motive for the [[circumcision]] war against boys.</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>==Applied ethics==</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>==Applied ethics==</div></td>\n</tr>\n\n<!-- diff cache key enwiki:diff:version:1.11a:oldid:489469890:newid:489636582 -->\n",
    "from": 489469890
  }
}