{
  "comment": "ISBNs (Build KH)",
  "timestamp": "2012-05-12T17:00:04Z",
  "revid": 492226061,
  "user": "Helpful Pixie Bot",
  "parentid": 492194166,
  "diff": {
    "to": 492226061,
    "*": "<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 58:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 58:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Mohist consequentialism}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Mohist consequentialism}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>[[Mohist consequentialism]], also known as state consequentialism,&lt;ref name=\"readings\"&gt;{{Cite book| title = Readings in classical Chinese philosophy | year = 2005 | last =Ivanhoe | first = P.J. | last2= Van Norden | first2= Bryan William |publisher = [[Hackett Publishing]] | isbn = 978-0-<del class=\"diffchange diffchange-inline\">87</del>-<del class=\"diffchange diffchange-inline\">220780</del>-6|page=60|quote=\"he advocated a form of state consequentialism, which sought to maximize three basic goods: the wealth, order, and population of the state}}&lt;/ref&gt; is an ethical theory which evaluates the moral worth of an action based on how much it contributes to the social harmony of a state.&lt;ref name=\"readings\"/&gt; The ''[[Stanford Encyclopedia of Philosophy]]'' describes Mohist consequentialism, dating back to the 5th century BC, as \"a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare.\"&lt;ref&gt;Fraser, Chris, \"[http://plato.stanford.edu/entries/mohism/ Mohism]\", ''[[The Stanford Encyclopedia of Philosophy]]'' , Edward N. Zalta.&lt;/ref&gt; Unlike utilitarianism, which views pleasure as a moral good, \"the basic goods in Mohist consequentialist thinking are... order, material wealth, and increase in population\".&lt;ref name=\"Cambridge\"&gt;{{Cite book| title = [[The Cambridge History of Ancient China]] | year = 1999 | last =Loewe | first = Michael | last2= Shaughnessy | first2= Edward L. |publisher = [[Cambridge University Press]] | isbn = 978-0-<del class=\"diffchange diffchange-inline\">52</del>-<del class=\"diffchange diffchange-inline\">147030</del>-8|page=761}}&lt;/ref&gt; During [[Mozi]]'s era, war and famines were common, and population growth was seen as a moral necessity for a harmonious society. The \"material wealth\" of Mohist consequentialism refers to [[Maslow's hierarchy of needs|basic needs]] like shelter and clothing, and the \"order\" of Mohist consequentialism refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability.&lt;ref name=\"Norden\"/&gt; [[Stanford University|Stanford]] [[sinologist]] [[David S. Nivison|David Shepherd Nivison]], in the ''[[The Cambridge History of Ancient China]]'', writes that the moral goods of Mohism \"are interrelated: more basic wealth, then more reproduction; more people, then more production and wealth... if people have plenty, they would be good, filial, kind, and so on unproblematically.\"&lt;ref name=\"Cambridge\"/&gt; In contrast to Bentham, Mozi did not believe that individual happiness was important, the consequences of the [[State (polity)|state]] outweigh the consequences of individual actions.&lt;ref name=\"Cambridge\"/&gt;</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>[[Mohist consequentialism]], also known as state consequentialism,&lt;ref name=\"readings\"&gt;{{Cite book| title = Readings in classical Chinese philosophy | year = 2005 | last =Ivanhoe | first = P.J. | last2= Van Norden | first2= Bryan William |publisher = [[Hackett Publishing]] | isbn = 978-0-<ins class=\"diffchange diffchange-inline\">87220</ins>-<ins class=\"diffchange diffchange-inline\">780</ins>-6|page=60|quote=\"he advocated a form of state consequentialism, which sought to maximize three basic goods: the wealth, order, and population of the state}}&lt;/ref&gt; is an ethical theory which evaluates the moral worth of an action based on how much it contributes to the social harmony of a state.&lt;ref name=\"readings\"/&gt; The ''[[Stanford Encyclopedia of Philosophy]]'' describes Mohist consequentialism, dating back to the 5th century BC, as \"a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare.\"&lt;ref&gt;Fraser, Chris, \"[http://plato.stanford.edu/entries/mohism/ Mohism]\", ''[[The Stanford Encyclopedia of Philosophy]]'' , Edward N. Zalta.&lt;/ref&gt; Unlike utilitarianism, which views pleasure as a moral good, \"the basic goods in Mohist consequentialist thinking are... order, material wealth, and increase in population\".&lt;ref name=\"Cambridge\"&gt;{{Cite book| title = [[The Cambridge History of Ancient China]] | year = 1999 | last =Loewe | first = Michael | last2= Shaughnessy | first2= Edward L. |publisher = [[Cambridge University Press]] | isbn = 978-0-<ins class=\"diffchange diffchange-inline\">521</ins>-<ins class=\"diffchange diffchange-inline\">47030</ins>-8|page=761}}&lt;/ref&gt; During [[Mozi]]'s era, war and famines were common, and population growth was seen as a moral necessity for a harmonious society. The \"material wealth\" of Mohist consequentialism refers to [[Maslow's hierarchy of needs|basic needs]] like shelter and clothing, and the \"order\" of Mohist consequentialism refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability.&lt;ref name=\"Norden\"/&gt; [[Stanford University|Stanford]] [[sinologist]] [[David S. Nivison|David Shepherd Nivison]], in the ''[[The Cambridge History of Ancient China]]'', writes that the moral goods of Mohism \"are interrelated: more basic wealth, then more reproduction; more people, then more production and wealth... if people have plenty, they would be good, filial, kind, and so on unproblematically.\"&lt;ref name=\"Cambridge\"/&gt; In contrast to Bentham, Mozi did not believe that individual happiness was important, the consequences of the [[State (polity)|state]] outweigh the consequences of individual actions.&lt;ref name=\"Cambridge\"/&gt;</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>{{quote|What is the purpose of houses? It is to protect us from the wind and cold of winter, the heat and rain of summer, and to keep out robbers and thieves. Once these ends have been secured, that is all. Whatever does not contribute to these ends should be eliminated.&lt;ref name=\"Norden\"&gt;{{Cite book| title = Introduction to Classical Chinese Philosophy | year = 2011 | last = Van Norden | first = Bryan W. | publisher = [[Hackett Publishing]] | isbn = 978-1-<del class=\"diffchange diffchange-inline\">60</del>-<del class=\"diffchange diffchange-inline\">384468</del>-0 | page = 52}}&lt;/ref&gt;|Mozi|''Mozi'' (5th century BC) Ch 20}}</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>{{quote|What is the purpose of houses? It is to protect us from the wind and cold of winter, the heat and rain of summer, and to keep out robbers and thieves. Once these ends have been secured, that is all. Whatever does not contribute to these ends should be eliminated.&lt;ref name=\"Norden\"&gt;{{Cite book| title = Introduction to Classical Chinese Philosophy | year = 2011 | last = Van Norden | first = Bryan W. | publisher = [[Hackett Publishing]] | isbn = 978-1-<ins class=\"diffchange diffchange-inline\">60384</ins>-<ins class=\"diffchange diffchange-inline\">468</ins>-0 | page = 52}}&lt;/ref&gt;|Mozi|''Mozi'' (5th century BC) Ch 20}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>===Modern ethics===</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>===Modern ethics===</div></td>\n</tr>\n<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 90:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 90:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Pragmatic ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Pragmatic ethics====</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Pragmatic ethics}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Pragmatic ethics}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>Associated with the [[pragmatism|pragmatists]], [[Charles Sanders Peirce]], [[William James]], and especially [[John Dewey]], pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).&lt;ref name=Lafollette2000&gt;{{Cite book | editor-first= Hugh | editor-last= Lafollette | series = Blackwell Philosophy Guides | edition = 1 | url= http://www.hughlafollette.com/papers/pragmati.htm | year = 2000 | month=February | title = The Blackwell Guide to Ethical Theory | isbn = 978-<del class=\"diffchange diffchange-inline\">0631201199</del> | publisher = [[Wiley-Blackwell]] | ref = harv}}&lt;/ref&gt;</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>Associated with the [[pragmatism|pragmatists]], [[Charles Sanders Peirce]], [[William James]], and especially [[John Dewey]], pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).&lt;ref name=Lafollette2000&gt;{{Cite book | editor-first= Hugh | editor-last= Lafollette | series = Blackwell Philosophy Guides | edition = 1 | url= http://www.hughlafollette.com/papers/pragmati.htm | year = 2000 | month=February | title = The Blackwell Guide to Ethical Theory | isbn = 978-<ins class=\"diffchange diffchange-inline\">0-631-20119-9</ins> | publisher = [[Wiley-Blackwell]] | ref = harv}}&lt;/ref&gt;</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>===Postmodern ethics===</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>===Postmodern ethics===</div></td>\n</tr>\n<tr>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 111:</td>\n  <td colspan=\"2\" class=\"diff-lineno\">Line 111:</td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Machine ethics====</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>====Machine ethics====</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>{{Main|Machine ethics}}</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">−</td>\n  <td class=\"diff-deletedline\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen | year = 2008 | month=November | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-<del class=\"diffchange diffchange-inline\">0195374049</del> | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n  <td class=\"diff-marker\">+</td>\n  <td class=\"diff-addedline\"><div>In ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in [[machine ethics]] will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation.&lt;ref name=Wallach2008&gt;{{Cite book  | first1 = Wendell | last1 = Wallach  | first2 = Colin | last2 = Allen | year = 2008 | month=November | title = Moral Machines: Teaching Robots Right from Wrong | isbn = 978-<ins class=\"diffchange diffchange-inline\">0-19-537404-9</ins> | publisher = [[Oxford University Press]] | location = USA | ref = harv}}&lt;/ref&gt; The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of [[List of machine learning algorithms|learning algorithms]], and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.</div></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"></td>\n</tr>\n<tr>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>==Applied ethics==</div></td>\n  <td class=\"diff-marker\">&#160;</td>\n  <td class=\"diff-context\"><div>==Applied ethics==</div></td>\n</tr>\n\n<!-- diff cache key enwiki:diff:version:1.11a:oldid:492194166:newid:492226061 -->\n",
    "from": 492194166
  },
  "minor": ""
}