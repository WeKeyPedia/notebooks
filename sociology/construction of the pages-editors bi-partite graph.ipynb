{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run \"libraries.ipynb\"\n",
    "\n",
    "from networkx.algorithms import bipartite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages = codecs.open(\"data/pagenames.txt\",\"r\", \"utf-8-sig\").readlines()\n",
    "pages = map(lambda x: x.strip(), pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing page-editor bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages_editors_graph = nx.Graph()\n",
    "\n",
    "\n",
    "def get_editors_set(page):\n",
    "    editors = []\n",
    "\n",
    "    revisions = json.load(codecs.open(\"data/revisions/%s.json\" % (page), \"r\", \"utf-8-sig\"))\n",
    "\n",
    "    if(len(revisions) == 0):\n",
    "        return editors\n",
    "    \n",
    "    revisions = pd.DataFrame(revisions)\n",
    "    \n",
    "    editors = revisions[revisions[\"userid\"] != 0][\"user\"].tolist()\n",
    "    # editors = map(lambda e: u\"%s\" % (e), editors)\n",
    "    editors = set(editors)\n",
    "    \n",
    "    # add the number of revisions per user\n",
    "    revisions_count = revisions.groupby(\"user\").groups\n",
    "    revisions_range = revisions.groupby(\"user\").agg({ \"timestamp\": [ np.min, np.max  ] })\n",
    "    # print editors\n",
    "\n",
    "    # delete weird users\n",
    "    # !!SOMEONE SHOULD CHECK THIS AGAIN: There is nan with page \"Four-dimensional space\"\n",
    "    editors = [ e for e in editors if e in revisions_count ]\n",
    "    \n",
    "    # store extra information about the edge\n",
    "    def info(x):\n",
    "        info = {\"revisions\": len(revisions_count[x]),\n",
    "                \"first revision\": revisions_range.ix[x][\"timestamp\"][\"amin\"],\n",
    "                \"last revision\": revisions_range.ix[x][\"timestamp\"][\"amax\"]\n",
    "               }\n",
    "        return info\n",
    "\n",
    "    editors = map(lambda x: (x, info(x)), editors)\n",
    "    \n",
    "    return editors\n",
    "\n",
    "for p in pages:\n",
    "    title = \"p:%s\" % (p)\n",
    "    # print p\n",
    "    e = get_editors_set(p)\n",
    "    \n",
    "    node_info = { \"revisions\": 0, \"first revision\": \"\", \"last revision\": \"\" }\n",
    "\n",
    "    if len(e) > 0:\n",
    "        node_info[\"revisions\"] = int(sum([ x[1][\"revisions\"] for x in e ]))\n",
    "        node_info[\"first revision\"] = str(np.min([ pd.to_datetime(x[1][\"first revision\"]) for x in e ]))\n",
    "        node_info[\"last revision\"] = str(np.max([ pd.to_datetime(x[1][\"last revision\"]) for x in e ]))\n",
    "    \n",
    "    pages_editors_graph.add_node(title, type=\"page\", attr_dict=node_info)\n",
    "\n",
    "    # add number of revisions to users\n",
    "    for editor in e:\n",
    "        editor_label = \"u:%s\" % (editor[0])\n",
    "        info = editor[1]\n",
    "        pages_editors_graph.add_node(editor_label, type=\"user\")\n",
    "        pages_editors_graph.add_edge(editor_label, title, attr_dict=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add extra information about editors\n",
    "editors = [ n for n in pages_editors_graph.nodes(data=True) if n[1][\"type\"] == \"user\" ]\n",
    "\n",
    "for editor in editors:\n",
    "    user = editor[0]\n",
    "    pages_editors_graph.node[user][\"revisions\"] = int(np.sum([ pages_editors_graph[user][edge][\"revisions\"] for edge in pages_editors_graph[user] ]))\n",
    "    pages_editors_graph.node[user][\"first revision\"] = str(np.min([ pd.to_datetime(pages_editors_graph[user][edge][\"first revision\"]) for edge in pages_editors_graph[user] ]))\n",
    "    pages_editors_graph.node[user][\"last revision\"] = str(np.max([ pd.to_datetime(pages_editors_graph[user][edge][\"last revision\"]) for edge in pages_editors_graph[user] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page nodes: 1239\n",
      "user nodes: 81604\n"
     ]
    }
   ],
   "source": [
    "pages_nodes = [ x[0] for x in  pages_editors_graph.nodes(data=True) if x[1][\"type\"] == \"page\" ]\n",
    "users_nodes = [ x[0] for x in  pages_editors_graph.nodes(data=True) if x[1][\"type\"] == \"user\" ]\n",
    "\n",
    "print \"page nodes: %s\" % (len(pages_nodes))\n",
    "print \"user nodes: %s\" % (len(users_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 82843\n",
      "edges: 259931\n"
     ]
    }
   ],
   "source": [
    "print \"nodes: %s\" % (len(pages_editors_graph.nodes()))\n",
    "print \"edges: %s\" % (len(pages_editors_graph.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(pages_editors_graph, \"data/pages-editors.gexf\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_bipartite(G, select, weight=\"weight\"):\n",
    "    selected = [ x[0] for x in G.nodes(data=True) if x[1][\"type\"] == select ]\n",
    "    results = bipartite.projected_graph(G, selected)\n",
    "\n",
    "    for u in results.nodes():\n",
    "        for v in results[u].keys():\n",
    "            w = len(set(G[u]) & set(G[v]))\n",
    "            results[u][v][weight] = w\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing page-page graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_graph = reduce_bipartite(pages_editors_graph, \"page\", \"coeditors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 1239\n",
      "edges: 596335\n"
     ]
    }
   ],
   "source": [
    "print \"nodes: %s\" % (len(page_graph.nodes()))\n",
    "print \"edges: %s\" % (len(page_graph.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(page_graph, \"data/pages-linked-by-coeditors.gexf\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing editor-editor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "editors_graph = reduce_bipartite(pages_editors_graph, \"user\", \"pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"nodes: %s\" % (len(editors_graph.nodes()))\n",
    "print \"edges: %s\" % (len(editors_graph.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nx.write_gexf(editors_graph, \"data/wikipedia-geometry/editors-linked-by-pages.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'I' and the 'me'</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Antonovsky</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Cicourel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abortion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abraham Moles</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: ['I' and the 'me', Aaron Antonovsky, Aaron Cicourel, Abortion, Abraham Moles]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df = pd.DataFrame(index=pages)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8dfcebc150e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcentrality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcloseness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloseness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbetweenness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coeditors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcurrent_flow_closeness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flow_closeness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coeditors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcurrent_flow_betweenness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flow_betweenness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coeditors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/networkx/algorithms/centrality/betweenness.pyc\u001b[0m in \u001b[0;36mbetweenness_centrality\u001b[0;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_shortest_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use Dijkstra's algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_dijkstra_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mendpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/networkx/algorithms/centrality/betweenness.pyc\u001b[0m in \u001b[0;36m_single_source_dijkstra_path_basic\u001b[0;34m(G, s, weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgedata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mvw_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0medgedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvw_dist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "centrality = nx.degree_centrality(page_graph)\n",
    "closeness = nx.closeness_centrality(page_graph)\n",
    "betweenness = nx.betweenness_centrality(page_graph, weight=\"coeditors\")\n",
    "current_flow_closeness = nx.current_flow_closeness_centrality(page_graph, weight=\"coeditors\")\n",
    "current_flow_betweenness = nx.current_flow_betweenness_centrality(page_graph, weight=\"coeditors\")\n",
    "#eigenvector = nx.eigenvector_centrality(page_graph)\n",
    "eigenvector = nx.eigenvector_centrality_numpy(page_graph, weight=\"coeditors\")\n",
    "\n",
    "for index in network_df.index:\n",
    "    t = \"p:%s\" % (index)\n",
    "    \n",
    "    network_df.ix[index,\"centrality\"] = centrality[t]\n",
    "    network_df.ix[index,\"closeness\"] = closeness[t]\n",
    "    network_df.ix[index,\"betweenness\"] = betweenness[t]\n",
    "    network_df.ix[index,\"current flow closeness\"] = current_flow_closeness[t]\n",
    "    network_df.ix[index,\"current flow betweenness\"] = current_flow_betweenness[t]\n",
    "    network_df.ix[index,\"eigenvector\"] = eigenvector[t]\n",
    "\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclusive editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_exclusive_editors(title):\n",
    "    nb = pages_editors_graph[\"p:%s\" % (title)]\n",
    "    # print nb.keys()\n",
    "    result = [n for n in nb.keys() if len(pages_editors_graph[n]) > 1 ]\n",
    "    return len(result)\n",
    "\n",
    "# print network_df.index[0:10].map(get_exclusive_editors)\n",
    "\n",
    "network_df[\"exclusive editors\"] = map(get_exclusive_editors, network_df.index)\n",
    "\n",
    "network_df[\"exclusive editors\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_df.to_csv(\"data/pages-linked-by-coeditors.stats.csv\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
